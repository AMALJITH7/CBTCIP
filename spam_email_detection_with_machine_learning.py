# -*- coding: utf-8 -*-
"""SPAM  EMAIL DETECTION WITH MACHINE LEARNING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zHSMVNVntm80fN2XIIlWJa5fq8tWG1eX
"""

import numpy as np
import pandas as pd

data=pd.read_csv('/content/drive/MyDrive/Cipherbytes/Spam Email Detection - spam.csv')
data

data=data[['v1','v2']]
data

dat=data.rename(columns={'v1': 'message', 'v2': 'text'}, inplace=True)
data

data.shape

def remove_punctuation(text):
  import string
  remover=str.maketrans('','',string.punctuation) #The str.maketrans method is used to create a translation table that maps each punctuation character to None (empty string)
  return text.translate(remover)

data['text']=data['text'].apply(remove_punctuation)
data.head()

import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords
stop_words=stopwords.words('english')

def remove_stopwords(text):
   text = [word.lower() for word in text.split() if word.lower() not in stop_words]
   return " ".join(text)

data['text']=data['text'].apply(remove_stopwords)
data.head()

data['message']=np.where(data['message']=='ham',1,0)
data.head()

x=data['text']
y=data['message']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=3)

print(x.shape)
print(x_train.shape)
print(x_test.shape)

x_train

y_train

from sklearn.feature_extraction.text import TfidfVectorizer
tfidvec=TfidfVectorizer(min_df=1)
tfidx_train=tfidvec.fit_transform(x_train)
tfidx_test=tfidvec.transform(x_test)

print(tfidx_train)

print(tfidx_test)

y_train = y_train.astype('int')
y_test = y_test.astype('int')

from sklearn.linear_model import LogisticRegression
pac=LogisticRegression()
pac.fit(tfidx_train,y_train)

from sklearn.metrics import accuracy_score
train_pred = pac.predict(tfidx_train)
ascore=accuracy_score(y_train,train_pred)
print(f"Accuracy of training data is : {round(ascore * 100, 2)}%")

test_pred=pac.predict(tfidx_test)
test_pred_series = pd.Series(test_pred)
test_pred_counts = test_pred_series.value_counts()
test_pred_counts

ascore=accuracy_score(y_test,test_pred)
print(f"Accuracy of test data is : {round(ascore * 100, 2)}%")

from sklearn.metrics import confusion_matrix
report=confusion_matrix(y_test,test_pred)
report

def output_label(n):
    if n[0] == 1:  # Assuming n is an array and you want to compare its first element
        return "HAM MAIL"
    elif n[0] == 0:  # Assuming n is an array and you want to compare its first element
        return "SPAM MAIL"


def manuel_testing(email):
  testing_news={"text":[email]}
  new_def_test=pd.DataFrame(testing_news)
  new_def_test["text"]=new_def_test["text"].apply(remove_punctuation,remove_stopwords)
  new_x_test=new_def_test["text"]
  new_xv_test=tfidvec.transform(new_x_test)
  test_pred=pac.predict(new_xv_test)
  return print("PREDICTION:-",output_label(test_pred))

email=input()
manuel_testing(email)